{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732b60d6",
   "metadata": {},
   "source": [
    "# K-Means Clustering with Scikit-Learn\n",
    "\n",
    "This notebook demonstrates K-Means clustering using scikit-learn library with comprehensive visualizations.\n",
    "\n",
    "## What is K-Means?\n",
    "K-Means is an unsupervised learning algorithm that partitions data into K clusters based on feature similarity.\n",
    "\n",
    "**Algorithm Steps:**\n",
    "1. Initialize K centroids randomly\n",
    "2. Assign each point to nearest centroid\n",
    "3. Update centroids as mean of assigned points\n",
    "4. Repeat steps 2-3 until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cce4d4",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6194d5",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data with 4 natural clusters\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, n_features=2, \n",
    "                         cluster_std=0.8, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Features: 2\")\n",
    "print(f\"Samples: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea195da1",
   "metadata": {},
   "source": [
    "## 3. Visualize Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ba6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c='blue', alpha=0.6, s=50)\n",
    "plt.title('Raw Data - Before K-Means Clustering', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data points are shown in blue. Now we'll apply K-Means to find clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ea74b",
   "metadata": {},
   "source": [
    "## 4. Apply K-Means with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24759b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit K-Means with K=4\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(f\"K-Means fitted successfully!\")\n",
    "print(f\"Number of clusters: {k}\")\n",
    "print(f\"Inertia (sum of squared distances): {kmeans.inertia_:.2f}\")\n",
    "print(f\"Number of iterations: {kmeans.n_iter_}\")\n",
    "print(f\"\\nCentroid coordinates:\")\n",
    "for i, centroid in enumerate(centroids):\n",
    "    print(f\"  Cluster {i}: ({centroid[0]:.3f}, {centroid[1]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff242035",
   "metadata": {},
   "source": [
    "## 5. Visualize Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for clusters\n",
    "colors = ['red', 'green', 'blue', 'orange', 'purple']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot 1: Clusters with centroids\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(k):\n",
    "    cluster_points = X[y_pred == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.6, s=50)\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], \n",
    "           c='black', marker='X', s=300, edgecolors='white', linewidth=2,\n",
    "           label='Centroids')\n",
    "\n",
    "plt.title('K-Means Clustering Results (K=4)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Cluster sizes\n",
    "plt.subplot(1, 2, 2)\n",
    "cluster_sizes = np.bincount(y_pred)\n",
    "bars = plt.bar(range(k), cluster_sizes, color=colors[:k])\n",
    "plt.title('Cluster Sizes', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Points')\n",
    "plt.xticks(range(k))\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa839182",
   "metadata": {},
   "source": [
    "## 6. Elbow Method - Finding Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inertia for different values of K\n",
    "inertias = []\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k_val in k_values:\n",
    "    kmeans_temp = KMeans(n_clusters=k_val, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(X)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=4, color='red', linestyle='--', linewidth=2, label='Optimal K=4')\n",
    "plt.title('Elbow Method - Finding Optimal Number of Clusters', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xticks(k_values)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The elbow appears around K=4, suggesting that is an optimal choice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afccd12",
   "metadata": {},
   "source": [
    "## 7. Predict Cluster for New Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0235116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new data points for prediction\n",
    "new_points = np.array([[-2, -2], [0, 0], [2, 2], [-2, 2]])\n",
    "new_predictions = kmeans.predict(new_points)\n",
    "\n",
    "print(\"New points and their predicted clusters:\")\n",
    "for point, cluster in zip(new_points, new_predictions):\n",
    "    print(f\"  Point {point} -> Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507fa6c",
   "metadata": {},
   "source": [
    "## 8. Visualize with New Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot original data\n",
    "for i in range(k):\n",
    "    cluster_points = X[y_pred == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.6, s=50)\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], \n",
    "           c='black', marker='X', s=300, edgecolors='white', linewidth=2,\n",
    "           label='Centroids')\n",
    "\n",
    "# Plot new data points\n",
    "for point, cluster in zip(new_points, new_predictions):\n",
    "    plt.scatter(point[0], point[1], c=colors[cluster], marker='s', \n",
    "               s=200, edgecolors='black', linewidth=2)\n",
    "\n",
    "plt.title('K-Means with New Data Points Predictions', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b045fa",
   "metadata": {},
   "source": [
    "## 9. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette score\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "silhouette_avg = silhouette_score(X, y_pred)\n",
    "davies_bouldin = davies_bouldin_score(X, y_pred)\n",
    "\n",
    "print(\"Clustering Quality Metrics:\")\n",
    "print(f\"  Inertia: {kmeans.inertia_:.2f}\")\n",
    "print(f\"  Silhouette Score: {silhouette_avg:.4f} (range: -1 to 1, higher is better)\")\n",
    "print(f\"  Davies-Bouldin Index: {davies_bouldin:.4f} (lower is better)\")\n",
    "print(f\"\\nSilhouette Score Interpretation:\")\n",
    "if silhouette_avg > 0.5:\n",
    "    print(\"    ✓ Strong cluster structure\")\n",
    "elif silhouette_avg > 0.3:\n",
    "    print(\"    ○ Reasonable cluster structure\")\n",
    "else:\n",
    "    print(\"    ✗ Weak cluster structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd77018",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **K-Means Algorithm**: Simple and effective for partitioning data into clusters\n",
    "2. **Centroid-based**: Minimizes within-cluster sum of squares\n",
    "3. **Elbow Method**: Helps determine optimal number of clusters\n",
    "4. **Scalability**: Efficient for large datasets\n",
    "5. **Limitations**: \n",
    "   - Requires specifying K in advance\n",
    "   - Sensitive to initialization\n",
    "   - Assumes spherical clusters\n",
    "\n",
    "### Applications:\n",
    "- Customer segmentation\n",
    "- Image compression\n",
    "- Document clustering\n",
    "- Anomaly detection\n",
    "\n",
    "### When to Use:\n",
    "✓ Data has clear, distinct clusters  \n",
    "✓ Need fast clustering  \n",
    "✓ Clusters are roughly spherical  \n",
    "✗ When K is unknown and data is sparse"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
